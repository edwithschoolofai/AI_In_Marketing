{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo - http://www.ai-writer.com/?page=view_result&type=article&id=14300&pass=7JClv4aayH\n",
    "\n",
    "### 마켓팅에서의 AI 실제 사례 \n",
    "\n",
    "![alt text](https://whatsthebigdata.files.wordpress.com/2017/02/ai_marketing.jpg?w=640 \"Logo Title Text 1\")\n",
    "\n",
    "- 잠재고객 타겟팅 (데이터를 분석하고 고객들을 점수화 합니다. 이는 고객들이 물건 구매나 영상 시청 등의 액션을 취할 것 같은 지에 근거합니다.) \n",
    "- 콘텐츠 제작 (어떤 종류의 콘텐츠가 고객들을 가장 잘 구매전환 시킬지)\n",
    "- 실시간 최적화 (어떻게 해야 콘텐츠를 고객에게 가장 잘 맞도록 실시간으로 최적화할지)\n",
    "- 기계들은 수년간 자동 콘텐츠 제작에 이용되어 왔습니다.특히 AP연합통신, 야후, 폭스와 같은 회사들이 꽤 오래 사용해오고 있죠.\n",
    "\n",
    "![alt text](https://blog.getresponse.com/uploads/2017/03/demandbasechart.png \"Logo Title Text 1\")\n",
    "\n",
    "### 이 분야의 스타트업들\n",
    "\n",
    "#### Appier\n",
    "\n",
    "![alt text](http://www.mobyaffiliates.com/wp-content/uploads/2015/11/appier.png \"Logo Title Text 1\")\n",
    "\n",
    "- Appier는 설립 5년차에 누적 약 500억 원 이상의 투자를 유치하였습니다. \n",
    "- 이 회사는 AI를 사용하여 잠재 고객들이 다음에 무엇을 할 지를 예측합니다.\n",
    "- 이 회사의 실시간 광고 최적화 엔진은 여러 개의 디지털 기기 간, 특히 스마트폰을 중심으로 잠재 고객들을 찾아냅니다.. \n",
    "- 잠재고객 데이터 풀을 더 진보되고 전문적인 버전으로 만들어주는데, 이는 과거에는 ‘cookie pools’이라고 불렸습니다.\n",
    "- 만일 당신의 고객들이 단지 신발만 구입하고자 했다면, 당장은 다른 신발을 더 사진 않을 지 몰라도 양말은 살 수 있지 않을까요? Appier에 가입해보세요\n",
    "\n",
    "#### Drawbridge\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/ai100-170927214644/95/artificial-intelligence-ai-100-startups-2017-75-638.jpg?cb=1510037429 \"Logo Title Text 1\")\n",
    "\n",
    "- Drawbridge는 cross-device 도달율에 관한 모든 것을 다루며, 특허를 가지고 있습니다. (on a “장치 사용에 기반한 인터넷장치 그룹핑 시스템”). \n",
    "- 약 500억 원 가량을 투자 받았습니다.\n",
    "- “익명의 ID”를 만드는데 이것은 광고뿐 아니라 더 많은 곳에 사용될 수 있습니다.(사기 탐지 등 말이죠)\n",
    "- 그들은 사람들이 언제 장비를 바꿔 사용할 지를 알 수 있으며, 광고주들은 그 장비간 이동 타이밍을 자본화할 수 있습니다.\n",
    "\n",
    "####  Insidesales.com \n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/il0wblpdsxgqdkrqwonw-signature-d9877cf01f81af06f005d08076d17a65d7a03928ceb1de73653a982ec29c2710-poli-170316163616/95/michael-plante-inside-sales-the-ai-revolution-6-638.jpg?cb=1490208673 \"Logo Title Text 1\")\n",
    "\n",
    "- 약 3천억원을 투자 받았으며, 2004년도에 설립되었습니다.\n",
    "- 당신이 큰 잠재적인 매출을 기대하고 있다면, 고객들 전부에게 한 번에 집중하려 했다간 아무것도 얻지 못 할 것입니다.\n",
    "- 이 회사는 구매전환 가능성이 가장 높은 상위 20%의 고객들을 예측할 수 있게 도와줍니다.\n",
    "\n",
    "#### Persado\n",
    "\n",
    "![alt text](https://beta.techcrunch.com/wp-content/uploads/2013/02/screen-shot-2013-02-13-at-11-43-05.png \"Logo Title Text 1\")\n",
    "\n",
    "- 이 회사는 문구와 단어들을 찾아내어, 잠재고객들에게 행동 유발을 극대화합니다. \n",
    "- 어떤 종류의 광고가 잠재고객들의 행동 유발을 극대화할 수 있을까요? 감성과 연관성이라는 요소를 발전시켜 나온 무언가 일 것입니다.\n",
    "- 이 회사의 솔루션은 마켓팅 funnel 단계 상 가장 첫 진입점에 관한 기술이라, 인수될 가능성이 있습니다. \n",
    "\n",
    "### Audience Targeting\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*Zhm1NMlmVywn0G18w3exog.png \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://recsysjd.files.wordpress.com/2016/09/ss.png?w=368&h=226 \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://i.imgur.com/bmW79NS.png \"Logo Title Text 1\")\n",
    "\n",
    "- 많이들 사용하는 LightFM 라이브러리에서는, 사용자-아이템 관계를 인수분해 기계 기능과 각 피처의 선형 임베딩을 학습하여 표현할 수 있습니다.\n",
    "- 이 두개의 representation 벡터를 곱하면 단위가 없는 점수가 나오는데\n",
    "- 이 점수로 순위를 매기면 주어진 사용자-아이템의 조합이 얼마나 좋은지 (또는 나쁜지)를 알수 있습니다.\n",
    "- 선형 인수분해 방법은 효과적이며 연산효율도 높습니다.\n",
    "- 하지만 심층 신경망은 더욱 의미있는 표상을 만들어내도록 개선될 수 있습니다.\n",
    "- TensorRec은 텐서플로우에서 돌아가는 최신 라이브러리로, 이 문제를 풀기 위해 개발되었습니다.\n",
    "- TensorRec은 학습과 예측에 필요한 쉬운 API를 제공하는 추천 알고리즘이며, 파이썬의 일반적인 머신러닝 툴들과 유사한 형태를 가지고 있습니다.\n",
    "\n",
    "![alt text](https://www.altoros.com/blog/wp-content/uploads/2018/03/multilayer-perceptron-with-tensorflow-architecture-for-recommender-systems-v1.png \"Logo Title Text 1\")\n",
    "\n",
    "- 여러분 각자의 표상과 손실 함수로도 실험해볼 수 있도록 유연하기 때문에, 여러분들은 이것으로 특정한 사용자-아이템 표상을 위한 전용 추천 시스템을 만들 수 있습니다.\n",
    "- 이 추천 엔진은, 직접적인 긍정과 부정 피드백으로부터 학습할 수도 있습니다.\n",
    "- 이 엔진은, 임의의 텐서플로우 그래프들도 representation 함수와,손실함수로써 사용될 수 있도록 해줍니다.\n",
    "- 또한 representation 함수와, 손실함수를 위한 합리적인 기본값도 제공해줍니다.\n",
    "- 이것으로 추천엔진의 스코어를 정할 수 있는데, 여기에 사용자-아이템의 특징들(아이디, 태그와 기타 메타데이타들)과 두개의 저차원 벡터 (“user representation”과 “item representation”)를 사용합니다.\n",
    "- 이 두 벡터의 내적이 사용자와, 사용자-아이템 간 관계의 점수입니다. — 가장 높은 점수를 최고의 추천이라고 예측합니다.\n",
    "-  The algorithm used to generate these representations, called the representation function, can be customized: anything from a straight-forward linear transform to a deep neural network can be applied\n",
    "-  It learns by comparing the scores it generates to actual interactions (likes/dislikes) between users and items. \n",
    "- The comparator is called the “loss function,” and TensorRec allows you to customize your own loss functions as well.\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/jfkirk/tensorrec/master/examples/system_diagram.png \"Logo Title Text 1\")\n",
    "\n",
    "\n",
    "#### 4 Steps!\n",
    "\n",
    "1. Transform input data into feature tensors for easy embedding.\n",
    "2. Transform user/item feature tensors into user/item representations (the representation function).\n",
    "3. Transform a pair of representations into a prediction.\n",
    "4. Transform predictions and truth values into a loss value (the loss function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorrec\n",
    "\n",
    "# Build the model with default parameters\n",
    "model = tensorrec.TensorRec()\n",
    "\n",
    "# Generate some dummy data\n",
    "interactions, user_features, item_features = tensorrec.util.generate_dummy_data(\n",
    "    num_users=100,\n",
    "    num_items=150,\n",
    "    interaction_density=.05\n",
    ")\n",
    "\n",
    "# Fit the model for 5 epochs\n",
    "model.fit(interactions, user_features, item_features, epochs=5, verbose=True)\n",
    "\n",
    "# Predict scores for all users and all items\n",
    "predictions = model.predict(user_features=user_features,\n",
    "                            item_features=item_features)\n",
    "\n",
    "# Calculate and print the recall at 10\n",
    "r_at_k = tensorrec.eval.recall_at_k(model, interactions,\n",
    "                                    k=10,\n",
    "                                    user_features=user_features,\n",
    "                                    item_features=item_features)\n",
    "print(np.mean(r_at_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Creation\n",
    "\n",
    "![alt text](https://www.kdnuggets.com/wp-content/uploads/RNN.jpg \"Logo Title Text 1\")\n",
    "\n",
    "http://www.ai-writer.com/?page=view_result&type=article&id=14300&pass=7JClv4aayH\n",
    "\n",
    "![alt text](http://keras.io/img/regular_stacked_lstm.png \"Logo Title Text 1\")\n",
    "\n",
    "- With AI marketers can automatically generate content for simple stories such as stock updates and sports reports. \n",
    "- You’ve probably even read content written by an algorithm without noticing it!\n",
    "- It may surprise you that the following opening sentence is a sports story written solely by an algorithm:\n",
    "\n",
    "#### “Tuesday was a great day for W. Roberts, as the junior pitcher threw a perfect game to carry Virginia to a 2-0 victory over George Washington at Davenport Field.”\n",
    "\n",
    "- Images, video? Use Generative Adversarial networks \n",
    "- Audio? Use WaveNet\n",
    "- Text? Use LSTM Recurrent Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
